{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a602f1cb-4f8e-427c-93a2-a35e4a704e84",
   "metadata": {},
   "source": [
    "# Transformerの詳細"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c7de2-07f1-459b-bd01-ce943abcfc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c1f201-1034-41c6-a536-2517c04158df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "text = \"time flies like an arrow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f88d3-a659-4252-b79b-824275f71c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931e269d-5e4c-442a-b6dd-afe717f2f02d",
   "metadata": {},
   "source": [
    "## スケール化ドット積アテンション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e113b-e1cb-471f-89fa-a635f35f24ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "token_emb = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "token_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e6c360-51cf-49f9-b6af-bd2eb0882f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Embeddingの埋め込みは文脈が考慮されない\n",
    "# 表記が同じトークンは同じベクトルを出力する\n",
    "# セルフアテンションを導入することで文脈を考慮したベクトルを求めるのが狙い\n",
    "\n",
    "# (batch_size, seq_len, hidden_dim)\n",
    "inputs_embeds = token_emb(inputs.input_ids)\n",
    "inputs_embeds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4ba70-8fb9-4874-9194-71093bcaf124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "\n",
    "# 実際はquery, key, valueを求めるときに独立した重み行列 W_Q, W_K, W_V を適用するが省略\n",
    "query = key = value = inputs_embeds\n",
    "dim_k = key.size(-1)\n",
    "\n",
    "# 各トークン間の距離を計算した行列\n",
    "scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n",
    "scores.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04bf15f-cea5-4a90-9f0b-625261fb4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.shape, key.transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32217de-2b84-41e2-af23-fb4079e67fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# attention weights\n",
    "weights = F.softmax(scores, dim=1)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985e135-bbe0-41d9-9f6b-f5ad1afcccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d378323-e56d-490b-96ca-98df8b0cd0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention weightsをvalueにかける\n",
    "attn_outputs = torch.bmm(weights, value)\n",
    "attn_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479ada4-c483-4237-aebb-7adcd52c8368",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape, value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29966f7-ed54-44a7-91ae-0a8f9080cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上記の処理を関数にまとめると\n",
    "def scaled_dot_product_attention(query, key, value):\n",
    "    dim_k = query.size(-1)\n",
    "    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return torch.bmm(weights, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb5ee8-d8ff-4a71-ad83-c7e96bb8ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attentionの出力は入力のベクトルと同じ形状\n",
    "attn_outputs = scaled_dot_product_attention(query, key, value)\n",
    "attn_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15e9bd-2c85-4494-a266-30059393c0ff",
   "metadata": {},
   "source": [
    "## マルチヘッドアテンション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370db819-a39b-4607-886b-7545e3d595c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# アテンションヘッド1つ\n",
    "# head_dimは最終的に必要なembed_dimをヘッド数で割ったサイズを指定する\n",
    "# BERTは特徴量次元が768で12個のヘッドがあるので768/12=64\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(embed_dim, head_dim)  # W_q\n",
    "        self.k = nn.Linear(embed_dim, head_dim)  # W_k\n",
    "        self.v = nn.Linear(embed_dim, head_dim)  # W_v\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        attn_outputs = scaled_dot_product_attention(\n",
    "            self.q(hidden_state), self.k(hidden_state), self.v(hidden_state))\n",
    "        return attn_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bba689-c438-4a1c-aafc-fa019c5fcd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = AttentionHead(768, 64)\n",
    "print(inputs_embeds.shape)\n",
    "attn_outputs = head(inputs_embeds)\n",
    "print(attn_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155baa0b-2a90-457c-a806-ba6315836b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        embed_dim = config.hidden_size\n",
    "        num_heads = config.num_attention_heads\n",
    "        head_dim = embed_dim // num_heads\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        # 複数のヘッドの出力をconcatする\n",
    "        x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)\n",
    "        x = self.output_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29ae63-2ae0-4209-bcf7-b1ff1ffeeacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_attn = MultiHeadAttention(config)\n",
    "attn_outputs = multihead_attn(inputs_embeds)\n",
    "attn_outputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57fce3-a107-4d2b-b7d0-d29ee835472e",
   "metadata": {},
   "source": [
    "## 順伝播層\n",
    "\n",
    "* 各トークンの埋め込みを独立に処理する\n",
    "* 位置単位順伝播層（position-wise feed-forward layer)\n",
    "* 隠れ層のサイズは埋め込みの4倍でGELUを使うのが一般的\n",
    "* nn.Linearは (batch_size, input_dim) が入力のときバッチ次元の各要素に独立に作用する\n",
    "* (batch_size, seq_len, hidden_dim) が入力のときはバッチと系列のすべてのトークン埋め込みに対して独立に作用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f0022-2e45-4ac6-9dd8-670f225acad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.linear_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b06ce-4cc4-4537-ab13-830c5d02c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc7f3b0-5e87-4a20-85c9-97771f9fbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.hidden_size, config.intermediate_size, config.hidden_dropout_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f2560-72bc-4730-a31f-1aa50668b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_forward = FeedForward(config)\n",
    "ff_outputs = feed_forward(attn_outputs)\n",
    "ff_outputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf120c-56af-4c8f-aedb-6995b3a13935",
   "metadata": {},
   "source": [
    "## レイヤー正規化の追加\n",
    "\n",
    "* Layer Normalization\n",
    "* Skip Connection\n",
    "* レイヤー正規化後置型: Transformerの論文の実装\n",
    "* レイヤー正規化前置型: 学習が安定する（こちらを使う）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5df192-1db1-4dfd-bcde-c3fc5bc743ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n",
    "        self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n",
    "        self.attention = MultiHeadAttention(config)\n",
    "        self.feed_forward = FeedForward(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # レイヤー正規化を適用\n",
    "        hidden_state = self.layer_norm_1(x)\n",
    "        # スキップ接続付きのアテンションを適用\n",
    "        x = x + self.attention(hidden_state)\n",
    "        # スキップ接続付きの順伝播層を適用\n",
    "        x = x + self.feed_forward(self.layer_norm_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7eea0-77a8-43c5-9f1b-f2f1a703ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = TransformerEncoderLayer(config)\n",
    "\n",
    "print(inputs_embeds.shape)\n",
    "outputs = encoder_layer(inputs_embeds)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c2b8f-b84c-4d75-8b45-8e855765937c",
   "metadata": {},
   "source": [
    "## 位置埋め込み\n",
    "\n",
    "* これまでのエンコーダ層はトークンの位置を考慮していない\n",
    "* データが大規模なら学習可能なパターン（位置IDのEmbeddingsを使う）を用いるのが一般的\n",
    "* sin/cosを組み合わせる絶対位置表現はデータが少ないときに有効\n",
    "* 相対位置表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae728c1a-da2b-4ec1-bca3-40dd56a27b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = nn.Embedding(config.vocab_size, \n",
    "                                             config.hidden_size)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n",
    "                                                config.hidden_size)\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # 入力系列に対する位置IDを作成\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)\n",
    "        # トークン埋め込みと位置埋め込みを作成\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        # トークン埋め込みと位置埋め込みを組み合わせる\n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e43e7d-44f1-4a58-8f49-5a9efbe5f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大系列長は512\n",
    "config.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df4509-6399-4c80-9b49-5d8aeb1f7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs.input_ids.shape)\n",
    "seq_length = inputs.input_ids.size(1)\n",
    "seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add386b-9c9c-4b13-b35b-6ff10aa554b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)\n",
    "position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7768d9e0-1399-4a69-a1b2-24ea8d54cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embeddings(config)\n",
    "embedding_layer(inputs.input_ids).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034965f7-46ed-49a0-b27e-e7f58c2db6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.num_hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d81706-ce18-412c-bc09-3f8c43e60729",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embeddings = Embeddings(config)\n",
    "        self.layers = nn.ModuleList([TransformerEncoderLayer(config) \n",
    "                                     for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1571dd-9d59-49ad-b2cb-7db7009c77f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各トークンの隠れ状態を返す\n",
    "encoder = TransformerEncoder(config)\n",
    "encoder(inputs.input_ids).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b52bc0-186a-49e5-934a-d1eacd829c49",
   "metadata": {},
   "source": [
    "## 分類ヘッドの追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8abfb22-b0cd-4b85-8875-a4a39a64d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerForSequenceClassification(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # [CSL]トークン（0番目）の隠れ状態のみ使う\n",
    "        x = self.encoder(x)[:, 0, :]\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b84310-edc9-4545-92a2-657da19d26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.num_labels = 3\n",
    "encoder_classifier = TransformerForSequenceClassification(config)\n",
    "encoder_classifier(inputs.input_ids).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
