{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecd67a9-c0f4-4c21-8a2a-423a39536387",
   "metadata": {},
   "source": [
    "# テキスト分類\n",
    "\n",
    "* DistilBERTをFine-tuningしてTwitterデータの感情検出器を作る\n",
    "* angry, love, fear, joy, sadness, surpriseの6感情"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e0e9d-eb99-467d-bfee-9105b2f78ea1",
   "metadata": {},
   "source": [
    "## データセット\n",
    "\n",
    "* [emotionsデータセット](https://huggingface.co/datasets/emotion)\n",
    "\n",
    "```\n",
    "Emotion は、怒り、恐れ、喜び、愛、悲しみ、驚きの 6 つの基本的な感情を含む英語の Twitter メッセージのデータセットです。詳細については、論文を参照してください\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a0882-830b-4de0-bcb2-0dbbea82aebb",
   "metadata": {},
   "source": [
    "### Hugging Face Datasets\n",
    "\n",
    "* `list_datasets()` でデータセット一覧を確認できる\n",
    "* `load_dataset()` でダウンロードできる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a10cc-dcef-4d1c-8dea-c31fa42b7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_datasets\n",
    "\n",
    "all_datasets = list_datasets()\n",
    "print(f\"There are {len(all_datasets)} datasets currently available on the Hub\")\n",
    "print(f\"The first 10 are: {all_datasets[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a91043-b899-46d1-9dee-3eb3af7e6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "emotions = load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56329f7a-8d74-4e9a-94d4-f4bf6a3426f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfedf0-7dea-45e6-b674-7e711b2844c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = emotions[\"train\"]\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b47b4-c42f-4261-a801-ffc7874c1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7720c5-de75-4a3a-872e-8bffb73cde58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82163118-82ae-41c9-a147-ae1cfba3c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d9a85-9d7e-418d-b8aa-b6775964a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff3d681-f208-4e54-b61c-b4819bdc7a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8499b5-1251-40fd-bdc9-480477e52e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[\"text\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c2569-23bb-4771-99fd-30f83a9c6374",
   "metadata": {},
   "source": [
    "### DataFrameへの変換\n",
    "\n",
    "* `set_format()` でDatasetの出力形式を変更できる\n",
    "* `int2str()` でラベルIDを文字列に変換できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82118b1-6a7b-4f69-ad70-e05a1288eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emotions.set_format(type=\"pandas\")\n",
    "\n",
    "# 出力がpandasのDataFrameになった\n",
    "emotions[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ab392-a544-429d-8dec-fde4a6bcd082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainの全データを取得\n",
    "df = emotions[\"train\"][:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c4c68-5abd-4b79-9d6a-338d686d209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions[\"train\"].features[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4529fb-8762-4a5b-a737-18061ce8541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions[\"train\"].features[\"label\"].int2str([0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c0899-7081-4651-b759-2a4bf1b7d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_int2str(row):\n",
    "    return emotions[\"train\"].features[\"label\"].int2str(row)\n",
    "\n",
    "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb1c488-2acf-4685-be1d-a2a3746841c0",
   "metadata": {},
   "source": [
    "### クラス分布の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7a1e4-f492-41eb-9f52-6fdd8ffbd205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
    "plt.title(\"Frequency of Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20decb05-4619-4316-82e5-9d1af05f78a8",
   "metadata": {},
   "source": [
    "### ツイートの長さはどれくらい？\n",
    "\n",
    "* Transformerモデルには最大コンテキストサイズという入力系列長の制限がある\n",
    "* DistilBERTは512トークン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7454f124-387d-47ac-97b9-1aa0193a8fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"].str.split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d4dfc-2450-4673-9070-6020b7150c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)\n",
    "df.boxplot(\"Words Per Tweet\", by=\"label_name\", grid=False, showfliers=False, color=\"black\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a174815-e7e8-4c75-a151-8b1db3c3a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの出力形式を戻す\n",
    "emotions.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2803f52-d1d4-42c6-a0c7-73c561428ae1",
   "metadata": {},
   "source": [
    "## テキストからトークンへ\n",
    "\n",
    "* 通常、最適な単語分割はコーパスから学習する\n",
    "* もっともシンプルなやり方は文字トークン化と単語トークン化\n",
    "* この2つのやり方もデータによって変わるので学習と言ってもよさそう"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4282b619-9c89-43fc-99d2-89504cfcce76",
   "metadata": {},
   "source": [
    "### 文字トークン化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad5d6e5-ce5d-44ab-86b0-410a1aca385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tokenizing text is a core task of NLP.\"\n",
    "tokenized_text = list(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034cc5c-8b22-49e1-ac2b-42dc3ce4bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(set(tokenized_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05594a-36d0-49ac-9bf7-991e4f1eed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_text)))}\n",
    "print(token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc694e5-443e-457a-a929-45264d11ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f52b1c-322f-415a-bd7c-78ea450fe7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [token2idx[token] for token in tokenized_text]\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f9c46-c60e-460f-bf2d-28377f13d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hotベクトルへの変換\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_ids = torch.tensor(input_ids)\n",
    "one_hot_encodings = F.one_hot(input_ids, num_classes=len(token2idx))\n",
    "one_hot_encodings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d84f68-3355-4fab-8033-1aecd826a4cd",
   "metadata": {},
   "source": [
    "### サブワードトークン化\n",
    "\n",
    "* 文字トークン化と単語トークン化の中間\n",
    "* コーパスからトークン化を学習する\n",
    "* 頻出単語は単語として使う、そうでないものはより小さな単位に分割する\n",
    "* WordPiece: BERTとDistilBERTのTokenizer\n",
    "* `AutoTokenizer.from_pretrained()` を使うと指定したモデルのTokenizerをロードできる\n",
    "* [Autoがついている場合](https://huggingface.co/docs/transformers/model_doc/auto)はモデル名から自動判定する\n",
    "* モデルに対応するTokenizerを使う必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a05480-d830-4661-a231-98f066126953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ba838-a95f-4447-9293-dda44204cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoクラスを使わずにモデルごとのクラスも使える\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(model_ckpt)\n",
    "distilbert_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e194451e-a9be-43f5-9285-b607d6878b45",
   "metadata": {},
   "source": [
    "* Tokenizerをメソッドとして使うとinput_idsに変換できる\n",
    "* `convert_ids_to_tokens` を使うとinput_idsをトークンに戻せる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b31fd-5fea-46a7-bd46-02b7eab01a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tokenizing text is a core task of NLP.\"\n",
    "encoded_text = tokenizer(text)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55022879-dc29-489a-8f96-3ba8a0d23a7e",
   "metadata": {},
   "source": [
    "* [CLS] と [SEP] のような特別なトークンが付与される（モデルによって異なる）\n",
    "* `##` は分割されたトークン、文字列に変換するときは前のトークンとマージされる\n",
    "* 一般的でない単語は `##` で分割されやすい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a7dca-50bd-4877-8f0d-a0f2d395b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af7f041-0b8c-4eb4-8c46-398208df383d",
   "metadata": {},
   "source": [
    "* `convert_to_tokens_to_string()` でトークン列を文字列に変換できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f28c9-824a-4979-9ed2-c4dd99ec0750",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.convert_tokens_to_string(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf41547-52a3-4923-ab36-1bcff7811304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ボキャブラリーサイズ\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1b564-0d1c-4dda-9f15-b2662cceea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大コンテキストサイズ\n",
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b72402-3a5f-466d-80af-45c09d103ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのforwardパスで期待するフィールド名\n",
    "tokenizer.model_input_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
